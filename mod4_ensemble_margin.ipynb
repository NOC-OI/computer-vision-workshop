{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 4 - Margin and Ensemble Classifiers\n",
    "\n",
    "Before the popularization of deep learning, many applied automatic classification algorithms were variations on ensemble or margin classifiers. Both types of classifiers operate on pre-defined features. As we will see later, this is fundamentally different from neural networks which can learn directly from the images. For now, we will make use of the features pulled from SPC data in the last module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "from sklearn import ensemble\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "sys.path.append(os.path.join(os.getcwd(),'utilities'))\n",
    "from display_utils import make_confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important new toolkit we are importing here is *sklearn*, short for scikit-image. It contains most of the tools we will use to explore margin and ensemble classifiers.\n",
    "\n",
    "For all the techinques discussed in the rest of this module, we will make use of the same features we computed before. We will also need to divide it into seperate sets for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : Ciliate 01 , num images: 424\n",
      "class 1 : Glob , num images: 16\n",
      "class 2 : Acantharea , num images: 24\n",
      "class 3 : Poop 01 , num images: 63\n",
      "class 4 : Bubble , num images: 331\n",
      "class 5 : Sphere 01 , num images: 38\n",
      "class 6 : Bad Seg , num images: 249\n",
      "class 7 : Akashiwo , num images: 447\n",
      "class 8 : Polykrikos , num images: 331\n",
      "class 9 : Nauplius , num images: 336\n",
      "class 10 : Ellipse 01 , num images: 43\n",
      "class 11 : Lingulodinium , num images: 653\n",
      "class 12 : Protoperidinium Feeding , num images: 11\n",
      "class 13 : Ciliate 02 , num images: 14\n",
      "class 14 : Chain 01 , num images: 352\n",
      "class 15 : Diatom chain , num images: 60\n",
      "class 16 : Round 01 , num images: 65\n",
      "class 17 : Phyto Mix 01 , num images: 895\n",
      "class 18 : Ciliate 03 , num images: 24\n",
      "class 19 : Ceratium fusus , num images: 1011\n",
      "class 20 : Avocado 01 , num images: 62\n",
      "class 21 : Ceratium furca two , num images: 38\n",
      "class 22 : Cochlodinium , num images: 332\n",
      "class 23 : Red Eye , num images: 44\n",
      "class 24 : Prorocentrum Skinny , num images: 472\n",
      "class 25 : Penate , num images: 135\n",
      "class 26 : Star 01 , num images: 34\n",
      "class 27 : Dual Blobs , num images: 81\n",
      "class 28 : Ceratium furca , num images: 1411\n",
      "class 29 : Blob Group , num images: 11\n",
      "class 30 : Prorocentrum , num images: 1112\n",
      "class 31 : Bubble Like , num images: 361\n",
      "class 32 : Skinny Mix 01 , num images: 2052\n",
      "class 33 : Aggregate Mix , num images: 7289\n",
      "class 34 : Protoperidinium sp , num images: 198\n",
      "class 35 : Blobble , num images: 400\n",
      "class 36 : Spear 01 , num images: 524\n",
      "class 37 : Sand , num images: 740\n",
      "Total class: 38 , Total images: 20678\n"
     ]
    }
   ],
   "source": [
    "# load in the data. first get all the file paths\n",
    "ptf = glob.glob(os.path.join(\"/media/storage/image_data/SPC_data/manual_labels_features/\",\"*.csv\"))\n",
    "\n",
    "# initalize a dictionary for the data. This will contain all the file paths and the associated features\n",
    "data = dict()\n",
    "\n",
    "# we will also create a flag and a listto give the labels a numeric value\n",
    "flag = 0\n",
    "cls_names = []\n",
    "\n",
    "for line in ptf:\n",
    "\n",
    "    # read in the data, but skip the image path\n",
    "    temp = np.genfromtxt(line, usecols=range(1,71),delimiter=\",\")\n",
    "    \n",
    "    # get the image path, making sure to specify that the data type is string\n",
    "    temp_path = np.genfromtxt(line, usecols= [0], delimiter=\",\", dtype=np.str)\n",
    "    \n",
    "    # for now, we will ignore any classes with fewer than 10 samples\n",
    "    if 10 < temp.shape[0]:\n",
    "        \n",
    "        # now we are creating a \"nested dictionary.\" Each element is referenced by the image id and contains the features\n",
    "        # and numeric class label\n",
    "        for img, feats in zip(temp_path, temp):\n",
    "            data[img] = {'features': feats, 'class': flag}\n",
    "            \n",
    "        # create a list of the names of the categories and the associated numbers\n",
    "        name = line.split('/')[-1].split('_')[0]\n",
    "        print(\"class\", str(flag), \":\", name, \n",
    "              \", num images:\", str(temp.shape[0]))\n",
    "        cls_names.append((flag, name))\n",
    "        \n",
    "        flag+=1\n",
    "\n",
    "print(\"Total class:\", str(flag), \", Total images:\", str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 38 classes, comprising a total of 20678 samples. The nested dictionary is how we will interact with the data. Each data point is identified by its image ID that is saved as a dictionary key.\n",
    "\n",
    "Note that we are using python 3.6 which by default preserves the order of the dictionary. That is, the order of the key-value pairs will remain the same as how they were inserted into the dictionary no matter what. If for some reason you use an earlier version of python, be aware that the order may not be preserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first sample is: SPCP2-1522716755-312771-000-584-2524-224-128.jpg\n"
     ]
    }
   ],
   "source": [
    "# to get a list of all the dictionary keys use Python's built in list command and the dictionary method keys()\n",
    "img_ids = list(data.keys())\n",
    "\n",
    "print(\"the first sample is:\", img_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this later to display images after they have been classifier. We can call up the information from that particular image by calling that key's associated values from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPCP2-1522716755-312771-000-584-2524-224-128.jpg has two keys that can be referenced: dict_keys(['features', 'class'])\n"
     ]
    }
   ],
   "source": [
    "# get the data related to a particular sample put the key in square brackets\n",
    "# remember, the data is store as a dictionary itself. We can also print those keys in the same way\n",
    "\n",
    "print(img_ids[0], \"has two keys that can be referenced:\", data[img_ids[0]].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the features and the class of that first sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the numeric class is: 0\n",
      "the features are: [  5.67235429e-01   8.06082589e-01   2.07103476e-02   8.06082589e-01\n",
      "   2.31120000e+04   8.23555686e-01   1.71543325e+02   0.00000000e+00\n",
      "   2.84408754e-01   2.12988031e-02   5.75023115e-05   1.03953474e-04\n",
      "   7.80014848e-09   1.38600425e-05   1.93731586e-09   2.59058582e-01\n",
      "   4.84876658e-02   2.20199150e-01   4.62453373e-02   9.70800133e-03\n",
      "   1.31577215e-01   3.45316281e+00   1.79048225e+00   2.35758892e+00\n",
      "   4.25905750e+00   6.33965540e+00   7.17331783e+00   7.08213941e+00\n",
      "   9.46854563e-01   9.37746789e-01   9.11843519e-01   8.76248868e-01\n",
      "   8.59548187e-01   8.64953747e-01   9.08297483e-01   9.03828887e-01\n",
      "   8.84937543e-01   8.45380756e-01   8.25986643e-01   8.34588555e-01\n",
      "   7.12060569e-01   6.21818771e-01   3.28782904e-01   7.30131012e-02\n",
      "   2.06799996e-02   2.69482227e-02   3.39578263e-01   3.40777531e-01\n",
      "   3.92849714e-01   5.25042430e-01   3.86037203e-01   8.28412190e-01\n",
      "   6.53627647e-03   5.30657990e-03   6.19726627e-03   8.81415748e-03\n",
      "   7.97889650e-03   1.21267275e-02   2.99716221e-03   2.34471189e-03\n",
      "   4.52606471e-03   8.25828231e-03   9.35631091e-03   1.39371760e-02\n",
      "   5.38336198e-02   5.41400982e-02   5.96717599e-02   7.35480302e-02\n",
      "   4.29941437e-02   3.35367335e-02]\n"
     ]
    }
   ],
   "source": [
    "# to retrieve the class\n",
    "print(\"the numeric class is:\", data[img_ids[0]]['class'])\n",
    "\n",
    "# and the features\n",
    "print(\"the features are:\",  data[img_ids[0]]['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data in the workspace, we need to divide it up for training and testing. That is we need to seperate out a subset of the training data to use as an independent set to assess how well the classifier is doing. \n",
    "\n",
    "To do the data dictionary needs to be randomized and split into a training and test set. Here we will use an 80-20 train-test split; 80% of the data will be used to train and 20% will be reserved for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new first entry is: SPCP2-1523395870-206094-000-924-2024-80-96.jpg\n"
     ]
    }
   ],
   "source": [
    "# to avoid copying the dictionary multiple times, we will randomize the list of keys (ie the image IDs) we made above.\n",
    "random.shuffle(img_ids)\n",
    "\n",
    "# print one out to double check\n",
    "print(\"The new first entry is:\", img_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut off for 80-20 split: 16542\n",
      "number of training images: 16542\n",
      "nubmer of test images: 4136\n"
     ]
    }
   ],
   "source": [
    "# now we can split the list into training and test sets based on the number of entries\n",
    "idx = 0.8*len(img_ids)\n",
    "\n",
    "train_ids = img_ids[0:int(idx)]  # this will copy all the image ids from 0 to the 80% cut-off\n",
    "test_ids = img_ids[int(idx)::]  # this will copy all the image ids from the cut-off to the end\n",
    "\n",
    "# double check\n",
    "print(\"cut off for 80-20 split:\", str(int(idx)))\n",
    "print(\"number of training images:\", str(len(train_ids)))\n",
    "print(\"nubmer of test images:\", str(len(test_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. Now that the data is imported into the workspace in an organized way, we can begin training and testing classifiers. The same training and test data will be used for the both margin and ensemble classifiers. \n",
    "\n",
    "## Margin classifiers\n",
    "\n",
    "A margin classifier seperates data in a space by assigning a distance between each point and the decision boundary. Imagine that we have just 2 features, $x_{1}$ and $x_{2}$, to seperate two classes. We can plot the points in a plane and find a line that seperates them.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg\">\n",
    "    <figcaption>\n",
    "        Points and hyperplanes. Courtesy: ZackWeinberg, via Wikipedia\n",
    "    </figcaption>\n",
    "</figure>\n",
    "        \n",
    "\n",
    "The line labeled $H_{3}$ is the best linear discriminant of this data. \n",
    "\n",
    "A classic and widely used margin classifier is the *support vector machine* (SVM). SVMs search a space, definied by the features, to find the optimal seperating hyperplane (ie a plane in many dimensions). In the example above, it would iteratively try many lines such as $H_{1}$ and $H_{2}$ before eventually settling on a particular plane.\n",
    "\n",
    "We will use the implimentation in SKLearn, svc -- a class that contains all functions need to train, test, and deplpoy a SVM. Do note however, that fitting a SVM is computationally expensive and scale quadratically. In other words, training an SVM with O(10k) samples becomes really time consuming and memory hungry.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ensemble classifiers\n",
    "\n",
    "Rather than relying on the results of a single classifer, ensemble classifier combine the results of many smaller classifiers. There are many ways of generating such a collection of computer classifiers. Here we will focus on the popular random forest (RFs) models. \n",
    "\n",
    "RFs build a collection of decision trees built from a random selection of the feature set. A single decision tree is a type of flow chart: each node in the tree is a test on a single feature and each branch denotes the outcome. A terminal node, or leaf, represents the tree's final classification.\n",
    "\n",
    "A single decsion tree tends to overfit the data -- it become really good at representing the training data but does not generalize well to new data. RFs get around this by creating many trees, using a random subsample of features and training examples for each tree. A new sample is then fed into every tree and the results averaged at the end to come to a final decision.\n",
    "\n",
    "To train a RF in python we will use the sklearn's ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we are only using a few of the RF parameters. There are many ways to modify this\n",
    "rf_clf = ensemble.RandomForestClassifier(n_estimators=30, n_jobs=8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not trained the classifier yet. The code above defines an instance *rf_clf* of the class *RandomForestClassifier*. The parameters we added define a few things:\n",
    "\n",
    "* n_estimators is the number of trees. For now we are just using 30\n",
    "* n_jobs parallalizes the process. It subdivides the process out to some number of cores. This speeds up training and is limited by the hardware you are working on. \n",
    "* verbose just tells sklearn they we want feedback as it is training. \n",
    "\n",
    "There are loads of other parameters that can change how the classifier behaves. For our purposes, mostly using defaults will suffice. Note that we are not exlicitly defining the number of features the will be used in each random tree. The default as set by sklearn is $\\sqrt(n_features)$. This is generally a good rule of thumb.\n",
    "\n",
    "To train the classifier we need to give it data. This is done with the *fit* method of the *RandomForestClassifier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features dim: (16542, 70)\n",
      "train labels dim: (16542,)\n"
     ]
    }
   ],
   "source": [
    "# to train it, feed in the features and labels\n",
    "\n",
    "# pull out the features for the training data\n",
    "# the next line uses \"list comprehension\" to pull out the feature vectors only from the trianing data\n",
    "train_features = [data[line]['features'] for line in train_ids]\n",
    "train_features = np.asarray(train_features)  # convert to an array\n",
    "\n",
    "# retrieve the numeric classes of the training data\n",
    "train_labels = [data[line]['class'] for line in train_ids]\n",
    "train_labels = np.asarray(train_labels)  # convert to an array\n",
    "\n",
    "# check to make sure these numbers are right. We expect the training features to be a matrix with \n",
    "# dimensions [n_images x n_features] and the training labels to be a matrix with dimensions [n_images x 1]\n",
    "print(\"train features dim:\", train_features.shape)\n",
    "print(\"train labels dim:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=8,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now plug into the fit method. this step might take a little while\n",
    "rf_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done! The classifier is trained. Now we can test it on the independent set that it has not seen yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test features dim: (4136, 70)\n",
      "test labels dim: (4136,)\n"
     ]
    }
   ],
   "source": [
    "# to test it, feed in the features and labels from the test data\n",
    "\n",
    "# pull out the features for the test data\n",
    "# the next line uses \"list comprehension\" to pull out the feature vectors only from the trianing data\n",
    "test_features = [data[line]['features'] for line in test_ids]\n",
    "test_features = np.asarray(test_features)  # convert to an array\n",
    "\n",
    "# retrieve the numeric classes of the training data\n",
    "test_labels = [data[line]['class'] for line in test_ids]\n",
    "test_labels = np.asarray(test_labels)  # convert to an array\n",
    "\n",
    "# check to make sure these numbers are right. We expect the test features to be a matrix with \n",
    "# dimensions [n_images x n_features] and the test labels to be a matrix with dimensions [n_images x 1]\n",
    "print(\"test features dim:\", test_features.shape)\n",
    "print(\"test labels dim:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706721470019 % correct\n"
     ]
    }
   ],
   "source": [
    "# now plug it into the trained classifier\n",
    "acc = rf_clf.score(test_features, test_labels)\n",
    "\n",
    "print(acc, '% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad. But we need a way of visualizing what classes it had trouble with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "/usr/local/anaconda/envs/pytorch/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the labels for the test set from the classifier\n",
    "preds = rf_clf.predict(test_features)\n",
    "\n",
    "# make a confusion matrix\n",
    "make_confmat(test_labels, preds, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
