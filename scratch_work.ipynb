{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Feature extraction\n",
    "\n",
    "To train and apply ensemble or margin classifiers like random forests or support vector machines, features must be measured from the images. Feature extraction, like region finding, requires a substantial amount of engineering and time and tweaking for a particular dataset.\n",
    "\n",
    "Feature extraction routines assume that candidate regions have already been identified. In this module we will extract features from an example ROI from the SPC dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import filters, morphology, measure, color, feature\n",
    "from scipy import ndimage, interpolate\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as ptch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file path of the image in the directory. here grab the diatom chain \n",
    "ptf = glob.glob(os.path.join(os.getcwd(), 'SPC*'))\n",
    "\n",
    "# We will grab the first item in the list\n",
    "img = cv2.imread(ptf[0])\n",
    "\n",
    "# check to make sure we got the right thing\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This region is one that we might have extracted using techniques for the previous module. Like when find the regions, we need to generate a binary mask to tell the computer what to focus on.\n",
    "\n",
    "## Get a binary mask\n",
    "\n",
    "To start the mask we will use a new edge detector called a Scharr filter. The Scharr filter is an operator similar to Canny that searchers for edges in the intensity image. It is well suited to finding high frequency edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the image gray\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# compute the edges\n",
    "edges_mag = filters.scharr(img_gray)\n",
    "\n",
    "# see what it looks like\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(edges_mag, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scharr filter returns gray scale values. Let's make it binary a setting a threshold that is 3 times the median value in the array. This makes our mask more apt to retain edges that using something like Otsu's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_med = np.median(edges_mag)\n",
    "\n",
    "edges_thresh = 3*edges_med\n",
    "edges = edges_mag >= edges_thresh\n",
    "\n",
    "# see what it looks like\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look too bad. But we want to fill in the boundary and select only the largest one for processing. To start with, we can use morphological operations to seal up some of those holes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will fill in some of the holes\n",
    "edges = morphology.closing(edges, morphology.square(3))\n",
    "filled_edges = ndimage.binary_fill_holes(edges)\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(filled_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hole filling has expanded the mask a bit. The region growing effectively got rid of the holes, but bloated the mask. Eroding, another morphological operation, will shrink it down again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_close = morphology.erosion(filled_edges, morphology.square(3))\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(img_close, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also got rid of some of the smaller noise. We can now use skimages *label* routine to find all the connected regions in the frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the label routine the closed image to register connected regions.\n",
    "label_img = morphology.label(img_close, neighbors=8, background=0)\n",
    "lab_img_color = color.label2rgb(label_img, image=img_gray)\n",
    "\n",
    "# plot the whole image and the subregion next to each other\n",
    "plt.imshow(lab_img_color, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yellow boundardy encompasses the diatom chain and gets most of the spines. Before analyzing it, we need to select only the largest boundary in the frame. Regionprops will extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use region props. But this time, have it retain all the properties it can measure\n",
    "props = measure.regionprops(label_img, img_gray)\n",
    "max_area = 0\n",
    "max_area_ind = 0\n",
    "for f in range(0,len(props)):\n",
    "    if props[f].area > max_area:\n",
    "        max_area = props[f].area\n",
    "        max_area_ind = f\n",
    "\n",
    "ii = max_area_ind\n",
    "\n",
    "# now just display that area with the bounding box to make sure it got the right one.\n",
    "\n",
    "# this selects only the pixels in the labeled image that are in the region with the biggest area\n",
    "bw_mask = (label_img) == props[ii].label\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(bw_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contours. The second argument defines the value along which to\n",
    "# find the contour.\n",
    "contours = measure.find_contours(bw_img, 0.5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "for n, contour in enumerate(contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "    \n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it found a lot of noise contours and objects inside the actual diatom chain we are interested in. But clearly, the largest one is organism. We can select the largest one much the same way as when we the largest regions for extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the max_contour length really low. \n",
    "# notice this is not the actual length of the boundary. We are using the \n",
    "# length of the list coordinates as a proxy.\n",
    "max_length = -1\n",
    "max_contour = []  # empty list for the contour\n",
    "for cc in contours:\n",
    "    if (len(cc) > max_length):\n",
    "        max_length = len(cc)\n",
    "        max_contour = cc\n",
    "        \n",
    "# check that grabbed the right one. \n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "\n",
    "# plot the biggest contout\n",
    "ax.plot(max_contour[:, 1], max_contour[:, 0], linewidth=2)\n",
    "    \n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this nice boundary to make a mask, we must place the list of coordinates into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array of zeros the same size as the original image\n",
    "boundary = np.zeros(img_gray.shape)\n",
    "\n",
    "# round the values of the contour to be whole numbers\n",
    "yy = np.round(max_contour[:, 1])\n",
    "xx = np.round(max_contour[:, 0])\n",
    "\n",
    "# now set the pixel coordinates to of the boundary as 1\n",
    "boundary[xx.astype(int), yy.astype(int)] = 1\n",
    "\n",
    "# plot it to make sure the coordinates are right\n",
    "plt.imshow(boundary, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! The points are not quite filled in. The plot function used above interpolated between the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to 4096 point contour\n",
    "interp_xx = interpolate.interp1d(range(0, max_length), max_contour[:, 0])\n",
    "interp_yy = interpolate.interp1d(range(0, max_length), max_contour[:, 1])\n",
    "new_space = np.linspace(0, max_length-1, 4096)\n",
    "c_xx = interp_xx(new_space)\n",
    "c_yy = interp_yy(new_space)\n",
    "\n",
    "# round\n",
    "xx = np.round(c_xx)\n",
    "yy = np.round(c_yy)\n",
    "\n",
    "# make integers\n",
    "xx = xx.astype(np.int)\n",
    "yy = yy.astype(np.int)\n",
    "\n",
    "# dimensions\n",
    "mm, nn = img_gray.shape\n",
    "\n",
    "# place \n",
    "np.place(xx, xx >= mm, mm-1)\n",
    "np.place(yy, yy >= nn, nn-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array of zeros the same size as the original image\n",
    "boundary = np.zeros(img_gray.shape)\n",
    "\n",
    "# now set the pixel coordinates to of the boundary as 1\n",
    "boundary[xx, yy] = 1\n",
    "\n",
    "# plot it to make sure the coordinates are right\n",
    "plt.imshow(boundary, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill = ndimage.binary_fill_holes(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Interpolate to 4096 point contour\n",
    "    interpX = interpolate.interp1d(range(0,max_length),max_contour[:,0])\n",
    "    interpY = interpolate.interp1d(range(0,max_length),max_contour[:,1])\n",
    "    newS = np.linspace(0,max_length-1,4096)\n",
    "    cX = interpX(newS)\n",
    "    cY = interpY(newS)\n",
    "    cPath = cX +1j*cY\n",
    "    FdAll = np.fft.fft(cPath)\n",
    "    #FdSave = np.absolute(FdAll[2:18])/np.absolute(FdAll[1])\n",
    "        \n",
    "    # Add to feature vector\n",
    "    #X[0:16] = FdSave\n",
    "        \n",
    "    # Simplify the boundary\n",
    "    cen = np.fft.fftshift(FdAll)\n",
    "    \n",
    "    # take first 10% of fourier coefficents\n",
    "    cen2 = np.hstack([np.zeros(1843), cen[1843:2253], np.zeros(1843)])\n",
    "    # Back project to simplified boundary\n",
    "    back = np.fft.ifft(np.fft.ifftshift(cen2))\n",
    "    \n",
    "    xx = np.round(back.real)\n",
    "    yy = np.round(back.imag)\n",
    "    \n",
    "    m = img_gray.shape[0]\n",
    "    n = img_gray.shape[1]\n",
    "    \n",
    "    xx = xx.astype(np.int)\n",
    "    yy = yy.astype(np.int)\n",
    "    \n",
    "    np.place(xx, xx >= m, m-1)\n",
    "    np.place(yy, yy >= n, n-1)\n",
    "    \n",
    "    simp = np.zeros([m,n])\n",
    "    simp[xx,yy] = 1To\n",
    "    \n",
    "    # Fill the simplified boundary\n",
    "    fill = ndimage.binary_fill_holes(simp).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fill * img_gray\n",
    "plt.imshow(temp, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros(img_gray.shape)\n",
    "cX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_mag = filters.scharr(img_gray)\n",
    "edges_med = np.median(edges_mag)\n",
    "edges_thresh = 3*edges_med\n",
    "edges = edges_mag >= edges_thresh\n",
    "edges = morphology.closing(edges, morphology.square(3))\n",
    "filled_edges = ndimage.binary_fill_holes(edges)\n",
    "#edges = morphology.erosion(filled_edges, morphology.square(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = filters.threshold_otsu(edges_mag)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_mag.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges_mag, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
