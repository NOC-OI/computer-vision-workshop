{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 - Fine-tuning ResNet toward plankton data\n",
    "\n",
    "We have seen that a neural network that was trained on a completely plankton-unrelated dataset (like ImageNet) still produces features that allow the classification of plankton data.\n",
    "Now, we can go a step further and *fine-tune* such a network to do plankton classification.\n",
    "This is akin to teaching a person without prior oceanographic experience how to recognize different types of fish, assuming that they are able to recognize other kinds of objects.\n",
    "\n",
    "In practice, CNNs are almost always fine-tuned (and not trained from scratch) for convergence reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import RandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from utilities.display_utils import imshow_tensor\n",
    "from utilities.split import stratified_random_split\n",
    "\n",
    "DATASET_PATH = \"/data1/mschroeder/Datasets/19-05-11 ZooScanNet/ZooScanSet/imgs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and transformation\n",
    "\n",
    "Image datasets can conveniently loaded with [`torchvision.datasets.ImageFolder`](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder).\n",
    "It assumes one folder for each class where the images are located.\n",
    "\n",
    "CNNs have a fixed input size. ResNets happen to be trained with 224x244 images. \n",
    "Therefore, we need to make sure that each image has the correct dimensions.\n",
    "`ImageFolder` has a `transform` parameter for that.\n",
    "After resizing, the images need to be converted to a PyTorch [`Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    # Resize every image to a 224x244 square\n",
    "    Resize((224,224)),\n",
    "    # Convert to a tensor that PyTorch can work with\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Images are located at at {DATASET_PATH}/{class_name}/{objid}.jpg\n",
    "dataset = ImageFolder(DATASET_PATH, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tensor and the label of the first example\n",
    "tensor, label = dataset[0]\n",
    "\n",
    "print(\"Class: {:d} ({})\".format(label, dataset.classes[label]))\n",
    "imshow_tensor(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / validation sets\n",
    "Supervise the training using a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val = stratified_random_split(dataset, test_size=0.2)\n",
    "print(\"{:,d} training examples.\".format(len(dataset_train)))\n",
    "print(\"{:,d} validation examples.\".format(len(dataset_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model\n",
    "\n",
    "We start with a pre-trained ResNet18 model.\n",
    "It was initially trained on ImageNet which happens to contain 1000 classes. However, our plankton dataset contains XXX classes. Therefore, we have to reset the classifier layer to the correct number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# get the number of features that are input to the fully connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# reset the fully connect layer\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "# Transfer model to GPU\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the optimizer\n",
    "\n",
    "We will train the network using [Stochastic Gradient Descend (SDG)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).\n",
    "In each iteration, the network parameters are updated in order to minimize a training criterion, in our case the [Cross Entropy](https://en.wikipedia.org/wiki/Cross_entropy) Loss.\n",
    "The better the predictions, the smaller the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128,\n",
    "                                           shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 2 epochs\n",
    "for epoch in range(2):\n",
    "    with tqdm_notebook(loader_train, desc=\"Training Epoch #{:d}\".format(epoch + 1)) as t:\n",
    "        for inputs, labels in t:\n",
    "            # Copy data to GPU\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            t.set_postfix(loss=loss.item())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Let's see how well our model performs.\n",
    "\n",
    "First, display some examplary images together with their ground-truth and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A data loader for the validation set with a batch size of 4 for demonstration purposes\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=4, num_workers=4)\n",
    "\n",
    "# Extract one batch\n",
    "images, labels = next(iter(loader_val))\n",
    "\n",
    "# Show images of the batch\n",
    "imshow_tensor(torchvision.utils.make_grid(images))\n",
    "print('Ground truth:', ', '.join('%5s' % dataset.classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# Run the batch through the model\n",
    "outputs = model(images.cuda())\n",
    "\n",
    "# Collect the predicted classes\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:', ', '.join('%5s' % dataset.classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a thorough evaluation of the whole dataset. In order to do that, we need to run the whole validation set through the network and record the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val_small = torch.utils.data.Subset(dataset_val, range(10000))\n",
    "loader_val_small = torch.utils.data.DataLoader(dataset_val_small, batch_size=128)\n",
    "\n",
    "labels_true = []\n",
    "labels_predicted = []\n",
    "\n",
    "# We don't need to calculate gradients\n",
    "with torch.no_grad():\n",
    "    with tqdm_notebook(loader_val_small, desc=\"Evaluating\") as t:\n",
    "        for inputs, labels in t:\n",
    "            # Copy data to GPU\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            labels_true.extend(labels.tolist())\n",
    "            labels_predicted.extend(predicted.tolist())\n",
    "\n",
    "\n",
    "print(classification_report(labels_true,\n",
    "                            labels_predicted,\n",
    "                            labels=np.arange(len(dataset.classes)),\n",
    "                            target_names=dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Compare the results to the previous classifiers.\n",
    "2. Try different [transformations](https://pytorch.org/docs/stable/torchvision/transforms.html).\n",
    "3. Try a different [model](https://pytorch.org/docs/stable/torchvision/models.html).\n",
    "4. What do you need to change to use a different dataset?\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this module, you learned how to use a folder of images to fine-tune a model in PyTorch.\n",
    "\n",
    "***What else?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
