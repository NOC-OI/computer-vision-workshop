{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 4 - Margin and Ensemble Classifiers\n",
    "\n",
    "Before the popularization of deep learning, many applied automatic classification algorithms were variations on ensemble or margin classifiers. Both types of classifiers operate on pre-defined features. As we will see later, this is fundamentally different from neural networks which can learn directly from the images. For now, we will make use of the features pulled from SPC data in the last module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "import sklearn\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important new toolkit we are importing here is *sklearn*, short for scikit-image. It contains most of the tools we will use to explore margin and ensemble classifiers.\n",
    "\n",
    "For all the techinques discussed in the rest of this module, we will make use of the same features we computed before. We will also need to divide it into seperate sets for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : Ciliate 01 , num samples: 424\n",
      "class 1 : Glob , num samples: 16\n",
      "class 2 : Acantharea , num samples: 24\n",
      "class 3 : Poop 01 , num samples: 63\n",
      "class 4 : Bubble , num samples: 331\n",
      "class 5 : Sphere 01 , num samples: 38\n",
      "class 6 : Bad Seg , num samples: 249\n",
      "class 7 : Akashiwo , num samples: 447\n",
      "class 8 : Polykrikos , num samples: 331\n",
      "class 9 : Nauplius , num samples: 336\n",
      "class 10 : Ellipse 01 , num samples: 43\n",
      "class 11 : Lingulodinium , num samples: 653\n",
      "class 12 : Protoperidinium Feeding , num samples: 11\n",
      "class 13 : Ciliate 02 , num samples: 14\n",
      "class 14 : Chain 01 , num samples: 352\n",
      "class 15 : Diatom chain , num samples: 60\n",
      "class 16 : Round 01 , num samples: 65\n",
      "class 17 : Phyto Mix 01 , num samples: 895\n",
      "class 18 : Ciliate 03 , num samples: 24\n",
      "class 19 : Ceratium fusus , num samples: 1011\n",
      "class 20 : Avocado 01 , num samples: 62\n",
      "class 21 : Ceratium furca two , num samples: 38\n",
      "class 22 : Cochlodinium , num samples: 332\n",
      "class 23 : Red Eye , num samples: 44\n",
      "class 24 : Prorocentrum Skinny , num samples: 472\n",
      "class 25 : Penate , num samples: 135\n",
      "class 26 : Star 01 , num samples: 34\n",
      "class 27 : Dual Blobs , num samples: 81\n",
      "class 28 : Ceratium furca , num samples: 1411\n",
      "class 29 : Blob Group , num samples: 11\n",
      "class 30 : Prorocentrum , num samples: 1112\n",
      "class 31 : Bubble Like , num samples: 361\n",
      "class 32 : Skinny Mix 01 , num samples: 2052\n",
      "class 33 : Aggregate Mix , num samples: 7289\n",
      "class 34 : Protoperidinium sp , num samples: 198\n",
      "class 35 : Blobble , num samples: 400\n",
      "class 36 : Spear 01 , num samples: 524\n",
      "class 37 : Sand , num samples: 740\n",
      "Total class: 38 Total images: 20678\n"
     ]
    }
   ],
   "source": [
    "# load in the data. first get all the file paths\n",
    "ptf = glob.glob(os.path.join(\"/media/storage/image_data/SPC_data/manual_labels_features/\",\"*.csv\"))\n",
    "\n",
    "# initalize a dictionary for the data. This will contain all the file paths and the associated features\n",
    "data = dict()\n",
    "\n",
    "# we will also create a flag and a listto give the labels a numeric value\n",
    "flag = 0\n",
    "cls_names = []\n",
    "\n",
    "for line in ptf:\n",
    "\n",
    "    # read in the data, but skip the image path\n",
    "    temp = np.genfromtxt(line, usecols=range(1,71),delimiter=\",\")\n",
    "    \n",
    "    # get the image path, making sure to specify that the data type is string\n",
    "    temp_path = np.genfromtxt(line, usecols= [0], delimiter=\",\", dtype=np.str)\n",
    "    \n",
    "    # for now, we will ignore any classes with fewer than 10 samples\n",
    "    if 10 < temp.shape[0]:\n",
    "        \n",
    "        # now we are creating a \"nested dictionary.\" Each element is referenced by the image id and contains the features\n",
    "        # and numeric class label\n",
    "        for img, feats in zip(temp_path, temp):\n",
    "            data[img] = {'features': feats, 'class': flag}\n",
    "            \n",
    "        # create a list of the names of the categories and the associated numbers\n",
    "        name = line.split('/')[-1].split('_')[0]\n",
    "        print(\"class\", str(flag), \":\", name, \n",
    "              \", num samples:\", str(temp.shape[0]))\n",
    "        cls_names.append((flag, name))\n",
    "        \n",
    "        flag+=1\n",
    "\n",
    "print(\"Total class:\", str(flag), \"Total images:\", str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 38 classes, comprising a total of 20678 samples. The nested dictionary is how we will interact with the data. Each data point is identified by its image ID that is saved as a dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first sample is: SPCP2-1522716755-312771-000-584-2524-224-128.jpg\n"
     ]
    }
   ],
   "source": [
    "# to get a list of all the dictionary keys use Python's built in list command and the dictionary method keys()\n",
    "img_ids = list(data.keys())\n",
    "\n",
    "print(\"the first sample is:\", img_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this later to display images after they have been classifier. We can call up the information from that particular image by calling that key's associated values from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPCP2-1522716755-312771-000-584-2524-224-128.jpg has two keys that can be referenced: dict_keys(['features', 'class'])\n"
     ]
    }
   ],
   "source": [
    "# get the data related to a particular sample put the key in square brackets\n",
    "# remember, the data is store as a dictionary itself. We can also print those keys in the same way\n",
    "\n",
    "print(img_ids[0], \"has two keys that can be referenced:\", data[img_ids[0]].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the features and the class of that first sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the numeric class is: 0\n",
      "the features are: [  5.67235429e-01   8.06082589e-01   2.07103476e-02   8.06082589e-01\n",
      "   2.31120000e+04   8.23555686e-01   1.71543325e+02   0.00000000e+00\n",
      "   2.84408754e-01   2.12988031e-02   5.75023115e-05   1.03953474e-04\n",
      "   7.80014848e-09   1.38600425e-05   1.93731586e-09   2.59058582e-01\n",
      "   4.84876658e-02   2.20199150e-01   4.62453373e-02   9.70800133e-03\n",
      "   1.31577215e-01   3.45316281e+00   1.79048225e+00   2.35758892e+00\n",
      "   4.25905750e+00   6.33965540e+00   7.17331783e+00   7.08213941e+00\n",
      "   9.46854563e-01   9.37746789e-01   9.11843519e-01   8.76248868e-01\n",
      "   8.59548187e-01   8.64953747e-01   9.08297483e-01   9.03828887e-01\n",
      "   8.84937543e-01   8.45380756e-01   8.25986643e-01   8.34588555e-01\n",
      "   7.12060569e-01   6.21818771e-01   3.28782904e-01   7.30131012e-02\n",
      "   2.06799996e-02   2.69482227e-02   3.39578263e-01   3.40777531e-01\n",
      "   3.92849714e-01   5.25042430e-01   3.86037203e-01   8.28412190e-01\n",
      "   6.53627647e-03   5.30657990e-03   6.19726627e-03   8.81415748e-03\n",
      "   7.97889650e-03   1.21267275e-02   2.99716221e-03   2.34471189e-03\n",
      "   4.52606471e-03   8.25828231e-03   9.35631091e-03   1.39371760e-02\n",
      "   5.38336198e-02   5.41400982e-02   5.96717599e-02   7.35480302e-02\n",
      "   4.29941437e-02   3.35367335e-02]\n"
     ]
    }
   ],
   "source": [
    "# to retrieve the class\n",
    "print(\"the numeric class is:\", data[img_ids[0]]['class'])\n",
    "\n",
    "# and the features\n",
    "print(\"the features are:\",  data[img_ids[0]]['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is imported into the workspace in an organized way, we can begin training and testing classifiers.\n",
    "\n",
    "## Margin classifiers\n",
    "\n",
    "A margin classifier seperates data in a space by assigning a distance between each point and the decision boundary. Imagine that we have just 2 features, $x_{1}$ and $x_{2}$, to seperate two classes. We can plot the points in a plane and find a line that seperates them.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg\">\n",
    "    <figcaption>\n",
    "        Points and hyperplanes. Courtesy: ZackWeinberg, via Wikipedia\n",
    "    </figcaption>\n",
    "</figure>\n",
    "        \n",
    "\n",
    "The line labeled $H_{3}$ is the best linear discriminant of this data. \n",
    "\n",
    "A classic and widely used margin classifier is the *support vector machine* (SVM). SVMs search a space, definied by the features, to find the optimal seperating hyperplane (ie a plane in many dimensions). In the example above, it would iteratively try many lines such as $H_{1}$ and $H_{2}$ before eventually settling on a particular plane.\n",
    "\n",
    "We will use the implimentation in SKLearn, svc -- a class that contains all functions need to train, test, and deplpoy a SVM. Do note however, that fitting a SVM is computationally expensive and scale quadratically. In other words, training an SVM with O(10k) samples becomes really time consuming and memory hungry.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
