{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 - Deep neural networks and feature extraction\n",
    "Neural networks (NN) belong to an entirely different family of learning algorithms called representation learning. Such classifiers learn what they think are most salient directly from the data. Until recently computers were not powerful enough to operate directly on dense data such as images. Instead, researchers used NNs with hand-engineered features were they operated as *de facto* feature selectors. \n",
    "\n",
    "The past ten years have seen a confluence of advances in computer processing and labeled datasets. Together, these have led to renewed interest and rapid development in NN algorithms. The underlying mechanism remains similar: feed the network labeled examples, see how it does, adjust paramters, and repeat. This process is done many millions of times to tune weights in a network.\n",
    "\n",
    "There are many specific architectures of neural networks. For most of this tutorial we will focus on using *deep residual networks* or ResNets. ResNets are a refinement of general Convolutional Neural Networks(CNNs) that allow for more efficent training. In essence, there are two distinct phases of a ResNet: feature extraction and classification. The earliest layers of a network are filters that are used to find local regions fitting some pattern in the image.\n",
    "\n",
    "It turns out, these early fitlers are quite general. That is, they do not change very much regardless of the dataset used for training. We can exploit that fact to use a pre-trained network as a feature extractor. So rather then spending lots of time engineering our our features, we will use a ResNet to pull out the information for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imported a lot of new stuff here. Most of it is related to pytorch, the library we will be using for running the ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "Pytoch ships with many preloaded models. Here we will call ResNet and run it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a pretrained network\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now our resnet model. It has the appropriate architecture and is already trained with ImageNet. **FILL IN DETAILS ABOUT IMAGE NET**\n",
    "\n",
    "Now let us take our diatom chain image and put it through the net and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "ptf = glob.glob(os.path.join(os.getcwd(), 'SPC*'))\n",
    "\n",
    "img = cv2.imread(ptf[0])\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the image dimensions are not square. For margin and ensemble classifiers, this is not an issue. But NN require that everything be the same size as it is put into the system. This is a consequence of the underlying math that governs these systems: for the filters to work, they must be applied to the same sized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resize the image to 226x226\n",
    "img_res = cv2.resize(img, (226, 226))\n",
    "\n",
    "plt.imshow(img_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the image looks kind of squished. This is a consequence of using a neural network. By resizing the images, we lose some of the scale that we have come to rely on to identify these organisms. In principle, the computer does not care about the scale. There are, however, methods to preserve the scale or re-insert that information in the network.\n",
    "\n",
    "For now, we will just pump the image through the network and see what it says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "\n",
    "# run through network and see what class it says. probably something wacky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not that helpful by itself. Since the model has not been trained with plankton data, it will just attempt to shoehorn the image into whatever class it is closest too.\n",
    "\n",
    "## Extracting features from the ResNet\n",
    "\n",
    "Instead of asking the pretrained model to classify the image, we can use it to pull out features. Here we will read out the weights associated with the final hidden layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract features from the final hidden layer\n",
    "feature_extractor = torch.nn.Sequential()\n",
    "\n",
    "# run image through and print dimensions\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken the image, run it throught the ResNet trained on ImageNet, and produced a vector of 512 features. These feature can now be used to train a second stage classifier. Basically, we have reduced all the hand engineered feature extraction to just a few lines of code.\n",
    "\n",
    "## Running all the data through\n",
    "\n",
    "Now we need to repeat the process for all the images we want to play with. Our expected output will be the # images by # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the transform to run batches of resized images\n",
    "\n",
    "# extract features to big ol' np array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80-20 train-test split\n",
    "\n",
    "# Train model, not sure # of trees\n",
    "\n",
    "# Run model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare result to hand-engineered features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss appending hand-engineered features to ResNet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
